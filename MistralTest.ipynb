{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b93ccee098149c7bcb9d433bedf35f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc5a9c54a1c44a709b8d9685824c71b2",
              "IPY_MODEL_705306ba4cad4679a94a7f2d4b708e3c",
              "IPY_MODEL_3ee17701f0b441c6bd3130763fedb910"
            ],
            "layout": "IPY_MODEL_91ae14c852c142338fa3d67a12891b02"
          }
        },
        "dc5a9c54a1c44a709b8d9685824c71b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e12e2ca2bf74309875d6f5e899dba25",
            "placeholder": "​",
            "style": "IPY_MODEL_cc94724a45ab46b990c79426ede44402",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "705306ba4cad4679a94a7f2d4b708e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f19dd16329fb40158fd9b52ccf4c8f0e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a72807d3813d4ae9a2f8ea5f87fc7f32",
            "value": 2
          }
        },
        "3ee17701f0b441c6bd3130763fedb910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cba888e46d28458e91db1ffef7c735a4",
            "placeholder": "​",
            "style": "IPY_MODEL_12c6453aa57942d2af58fcff8059e61b",
            "value": " 2/2 [01:11&lt;00:00, 33.46s/it]"
          }
        },
        "91ae14c852c142338fa3d67a12891b02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e12e2ca2bf74309875d6f5e899dba25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc94724a45ab46b990c79426ede44402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f19dd16329fb40158fd9b52ccf4c8f0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72807d3813d4ae9a2f8ea5f87fc7f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cba888e46d28458e91db1ffef7c735a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12c6453aa57942d2af58fcff8059e61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w6AmY1N2UFQA"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch datasets\n",
        "!pip install -q accelerate==0.21.0 \\\n",
        "                peft==0.4.0 \\\n",
        "                bitsandbytes==0.40.2 \\\n",
        "                transformers==4.31.0 \\\n",
        "                trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "dXXNhDL3W_Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "5DwuJYSBXeMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoConfig\n",
        "\n",
        "model_identifier = 'mistralai/Mistral-7B-Instruct-v0.1'\n",
        "config = AutoConfig.from_pretrained(model_identifier)\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(model_identifier, trust_remote_code=True)\n",
        "text_tokenizer.pad_token = text_tokenizer.eos_token\n",
        "text_tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "1UPFZs6mVQXW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "enable_4bit_loading = True\n",
        "float_precision_dtype = \"float16\"\n",
        "quantization_format = \"nf4\"\n",
        "enable_double_quantization = False\n",
        "dtype_object = getattr(torch, float_precision_dtype)\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=enable_4bit_loading,\n",
        "    bnb_4bit_quant_type=quantization_format,\n",
        "    bnb_4bit_compute_dtype=dtype_object,\n",
        "    bnb_4bit_use_double_quant=enable_double_quantization,\n",
        ")"
      ],
      "metadata": {
        "id": "FQ7qImLkX2IM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_identifier,\n",
        "    quantization_config=quantization_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "9b93ccee098149c7bcb9d433bedf35f8",
            "dc5a9c54a1c44a709b8d9685824c71b2",
            "705306ba4cad4679a94a7f2d4b708e3c",
            "3ee17701f0b441c6bd3130763fedb910",
            "91ae14c852c142338fa3d67a12891b02",
            "8e12e2ca2bf74309875d6f5e899dba25",
            "cc94724a45ab46b990c79426ede44402",
            "f19dd16329fb40158fd9b52ccf4c8f0e",
            "a72807d3813d4ae9a2f8ea5f87fc7f32",
            "cba888e46d28458e91db1ffef7c735a4",
            "12c6453aa57942d2af58fcff8059e61b"
          ]
        },
        "id": "DixkuoNeYRo4",
        "outputId": "388362b3-7e9f-411d-c288-42deb7ec4326"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b93ccee098149c7bcb9d433bedf35f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "fjOF1kWOcOwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "text_generation_pipeline = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=text_tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.21,\n",
        "    repetition_penalty=1.15,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=350,\n",
        ")\n",
        "\n",
        "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
      ],
      "metadata": {
        "id": "ybhGihpRalvq"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "M29GGj9Wfzn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "oWhBj86xf-Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "UVCU9cuqmzGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "kU0QAACIm7q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import os\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "import pandas as pd\n",
        "import time\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "PROMPT_TEXT = \"\"\"\n",
        "[INST]\n",
        "Please answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Answer the question based on the above context:\n",
        "\n",
        "{question}\n",
        "\n",
        "A. {A}\n",
        "B. {B}\n",
        "C. {C}\n",
        "D. {D}\n",
        "\n",
        "Only write one letter for the answer: A, B, C, or D\n",
        "[/INST]\n",
        "\"\"\"\n",
        "#os.environ['OPENAI_API_KEY'] = # Entire key here\n",
        "CHROMA_DB_PATH = \"biology_lecture_notes_chroma2\"\n",
        "start_time = time.time()\n",
        "embedding_func = OpenAIEmbeddings()\n",
        "chroma_db = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embedding_func)\n",
        "df = pd.read_csv('college_biology_test.csv')\n",
        "accuracy = 0\n",
        "for index in df.index:\n",
        "    query = df['Question'][index]\n",
        "    #print(\"query \", query)\n",
        "    choice_a = df['A'][index]\n",
        "    choice_b = df['B'][index]\n",
        "    choice_c = df['C'][index]\n",
        "    choice_d = df['D'][index]\n",
        "    # perform vector search\n",
        "    results = chroma_db.similarity_search_with_relevance_scores(query, k = 3)\n",
        "    #prompt_template = ChatPromptTemplate.from_template(PROMPT_TEXT)\n",
        "    context = \"\\n\\n - - - \\n\\n\".join([doc.page_content for doc, _ in results])\n",
        "    prompt = PromptTemplate(\n",
        "      input_variables=[\"context\", \"question\",\"A\", \"B\", \"C\", \"D\"],\n",
        "      template=PROMPT_TEXT,\n",
        "    )\n",
        "    llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)\n",
        "    response = llm_chain.invoke({\"context\":context,\n",
        "                      \"question\": query,\n",
        "                      \"A\":choice_a,\n",
        "                      \"B\":choice_b,\n",
        "                      \"C\":choice_c,\n",
        "                      \"D\":choice_d,})\n",
        "    #prompt = prompt_template.format(context=context, question=query, A=choice_a, B=choice_b, C=choice_c, D=choice_d)\n",
        "    #print(\"prompt \", prompt)\n",
        "    #sources = [doc.metadata for doc, _ in results]\n",
        "    #response = mistral_llm.predict(prompt)\n",
        "    letter_response = response[\"context\"][-2]\n",
        "    print(\"Response \", response)\n",
        "    print(\"first letter \", letter_response)\n",
        "    label = df['Label'][index]\n",
        "    print(\"label \", label)\n",
        "    if letter_response == label:\n",
        "        accuracy += 1\n",
        "        print(\"accuracy increase \", accuracy)\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time} seconds\")\n",
        "print(\"accuracy \", accuracy/df.shape[0])"
      ],
      "metadata": {
        "id": "SRiPgVLlc_qK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}